{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87a9dfb3-3586-4a7d-8df6-b336e111ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(\"..\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b98d3e38-543f-446c-a88a-57945bfc1d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtsystem import openai, bedrock, ollama, anthropic, render, tasks, instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba481a77-1403-46b3-9bbf-ac58036f42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks.load('../data/optimize-genai-2024-0418.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2645ec31-c96c-4704-aaa2-689aee1bcf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_99279 th {\n",
       "  font-size: 10pt;\n",
       "  text-align: left;\n",
       "}\n",
       "#T_99279 td {\n",
       "  text-align: left;\n",
       "  word-wrap: break-word;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "}\n",
       "#T_99279 .index_name {\n",
       "  display: none;\n",
       "}\n",
       "#T_99279 .row_heading {\n",
       "  display: none;\n",
       "}\n",
       "#T_99279  .blank {\n",
       "  display: none;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_99279\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_99279_level0_col0\" class=\"col_heading level0 col0\" >Task</th>\n",
       "      <th id=\"T_99279_level0_col1\" class=\"col_heading level0 col1\" >System</th>\n",
       "      <th id=\"T_99279_level0_col2\" class=\"col_heading level0 col2\" >Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_99279_row0_col0\" class=\"data row0 col0\" >Reduce LLM inference cost</td>\n",
       "      <td id=\"T_99279_row0_col1\" class=\"data row0 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row0_col2\" class=\"data row0 col2\" >How to reduce LLM runtime or inference cost?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_99279_row1_col0\" class=\"data row1 col0\" >Improve LLM accuracy</td>\n",
       "      <td id=\"T_99279_row1_col1\" class=\"data row1 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row1_col2\" class=\"data row1 col2\" >How to improve LLM accuracy?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_99279_row2_col0\" class=\"data row2 col0\" >Improve LLM performance</td>\n",
       "      <td id=\"T_99279_row2_col1\" class=\"data row2 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row2_col2\" class=\"data row2 col2\" >How to improve LLM performance?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_99279_row3_col0\" class=\"data row3 col0\" >Effectively deploy LLMs</td>\n",
       "      <td id=\"T_99279_row3_col1\" class=\"data row3 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row3_col2\" class=\"data row3 col2\" >How to most effectively deploy LLMs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_99279_row4_col0\" class=\"data row4 col0\" >Scale LLMs efficiently</td>\n",
       "      <td id=\"T_99279_row4_col1\" class=\"data row4 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row4_col2\" class=\"data row4 col2\" >How to scale LLMs efficiently?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_99279_row5_col0\" class=\"data row5 col0\" >Training data selection</td>\n",
       "      <td id=\"T_99279_row5_col1\" class=\"data row5 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row5_col2\" class=\"data row5 col2\" >What to perform training data selection and curation for LLMs?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_99279_row6_col0\" class=\"data row6 col0\" >Ethical use of GenAI</td>\n",
       "      <td id=\"T_99279_row6_col1\" class=\"data row6 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row6_col2\" class=\"data row6 col2\" >How to ensure the ethical use of Generative AI?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_99279_row7_col0\" class=\"data row7 col0\" >Bias and fairness in GenAI</td>\n",
       "      <td id=\"T_99279_row7_col1\" class=\"data row7 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row7_col2\" class=\"data row7 col2\" >What to handle bias and fairness in Generative AI models?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_99279_row8_col0\" class=\"data row8 col0\" >LLM Explainability</td>\n",
       "      <td id=\"T_99279_row8_col1\" class=\"data row8 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row8_col2\" class=\"data row8 col2\" >How to perform LLM interpretability and explainability?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_99279_row9_col0\" class=\"data row9 col0\" >LLM adversarial attacks</td>\n",
       "      <td id=\"T_99279_row9_col1\" class=\"data row9 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row9_col2\" class=\"data row9 col2\" >How to make Generative AI applications more robust against adversarial attacks?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_99279_row10_col0\" class=\"data row10 col0\" >LLM regulatory compliance</td>\n",
       "      <td id=\"T_99279_row10_col1\" class=\"data row10 col1\" >Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row10_col2\" class=\"data row10 col2\" >How do we balance innovation with regulatory compliance of Generative AI applications?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_99279_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_99279_row11_col0\" class=\"data row11 col0\" >LLM emerging trends</td>\n",
       "      <td id=\"T_99279_row11_col1\" class=\"data row11 col1\" >Only respond with a markdown table with the top 5 latest emerging trends or technologies ranked by order of most popular first. Include columns for Popularity, Emerging Trend or Technology, Description, Recommended by Experts (with 3 top industry analysts or Big5 consultants or VCs recommending the trend or technology), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.</td>\n",
       "      <td id=\"T_99279_row11_col2\" class=\"data row11 col2\" >How to enhance our Generative AI application?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x10b06c410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "render.df(tasks.list(0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "821c2af3-d104-408f-8669-b6161acbd048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['240420094946-How-to-reduce-LLM-runtime-or-inference-cost.json',\n",
       " '240420101611-How-to-scale-LLMs-efficiently.json',\n",
       " '240420095000-How-to-improve-LLM-accuracy.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.CHAT.search('LLM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc890636-f9ca-4183-bea9-6ee02dfc2050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat loaded from openai_chats/240420094946-How-to-reduce-LLM-runtime-or-inference-cost.json\n"
     ]
    }
   ],
   "source": [
    "chat = openai.CHAT.load('240420094946-How-to-reduce-LLM-runtime-or-inference-cost.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1087224b-3fa0-413a-9e0e-e2de67b0c664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "⚙️ *Only respond with a markdown table with the top 5 most effective strategies ranked by order of most popular first. Include columns for Popularity, Strategy, Description, Examples (with 3 examples), Paper (with link to latest paper about the strategy). Be factual in your response. When facts are not available, do not generate response. Don't explain your response.*\n",
       "\n",
       "👤 **How to reduce LLM runtime or inference cost?**\n",
       "\n",
       "💬\n",
       "| Popularity | Strategy                | Description                                                  | Examples                                   | Paper                                                                                     |\n",
       "|------------|-------------------------|--------------------------------------------------------------|--------------------------------------------|-------------------------------------------------------------------------------------------|\n",
       "| 1          | Quantization            | Reducing the precision of the model's parameters             | INT8, FP16, Binary                         | [Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference](https://arxiv.org/abs/1712.05877) |\n",
       "| 2          | Pruning                 | Removing redundant or non-critical parts of the model        | Weight pruning, Unit pruning, Sparse pruning | [To Prune, or Not to Prune: Exploring the Efficacy of Pruning for Model Compression](https://arxiv.org/abs/1710.01878) |\n",
       "| 3          | Distillation            | Training a smaller model to mimic a larger one               | Teacher-student, Soft targets, FitNets     | [Distilling the Knowledge in a Neural Network](https://arxiv.org/abs/1503.02531)          |\n",
       "| 4          | Efficient Architectures | Designing or using models that require fewer computations    | MobileBERT, EfficientNet, TinyBERT         | [MobileBERT: a Compact Task-Agnostic BERT for Resource-Limited Devices](https://arxiv.org/abs/2004.02984) |\n",
       "| 5          | Caching                 | Storing previous computations to avoid redundant processing  | Layer output caching, Embedding caching, Activation caching | [Increasing the Actionability of Large-Scale Language Models Through Caching](https://arxiv.org/abs/2102.08473) |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render.chat(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd99c42-56fd-45b6-b602-42fb9b0d4f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks.get('Improve LLM accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "212901e2-2df9-44ef-9e2d-2a7623725aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Popularity | Strategy                | Description                                                  | Examples                                       | Paper                                                                                     |\n",
       "|------------|-------------------------|--------------------------------------------------------------|------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
       "| 1          | Fine-tuning             | Adjusting model parameters on specific data after pretraining| GPT-3 on legal documents, BERT on tweets, T5 on medical records | [Fine-Tuning Language Models from Human Preferences](https://arxiv.org/abs/1909.08593)  |\n",
       "| 2          | Data Augmentation       | Expanding training dataset by modifying existing data        | Synonym replacement, Back translation, Random insertion | [Data Augmentation for NLP](https://arxiv.org/abs/2105.03075)                             |\n",
       "| 3          | Transfer Learning       | Applying knowledge from one domain to a related one          | ULMFiT for sentiment analysis, BERT for question answering, ELMo for named entity recognition | [A Survey on Transfer Learning](https://ieeexplore.ieee.org/document/5288526)            |\n",
       "| 4          | Ensemble Methods        | Combining multiple models to improve performance             | Voting classifiers, Stacking, Bagging          | [Ensemble Learning to Improve Machine Learning Outcomes](https://arxiv.org/abs/2012.01284)|\n",
       "| 5          | Regularization          | Techniques to reduce overfitting                             | Dropout, L2 regularization, Early stopping     | [Regularization for Deep Learning: A Taxonomy](https://arxiv.org/abs/1710.10686)         |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render.md(openai.chat(*task, tokens=1024, reset=True, cache=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e87e88f0-6d37-427f-bc08-92c1cdd7301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tasks.get('Improve LLM performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a10e096-9682-4d8f-9e23-f696d64b5c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Popularity | Strategy                | Description                                                  | Examples                                       | Paper                                                                                     |\n",
       "|------------|-------------------------|--------------------------------------------------------------|------------------------------------------------|-------------------------------------------------------------------------------------------|\n",
       "| 1          | Fine-tuning             | Adjusting model parameters on specific task data             | GPT-3 on legal documents, BERT on tweets, T5 on summarization tasks | [Fine-Tuning Language Models from Human Preferences](https://arxiv.org/abs/1909.08593)  |\n",
       "| 2          | Data Augmentation       | Expanding training dataset with variations of existing data  | Synonym replacement, Back translation, Text surface transformation | [Data Augmentation for NLP](https://arxiv.org/abs/2105.03075)                            |\n",
       "| 3          | Transfer Learning       | Applying knowledge from one domain to a related one          | ULMFiT for sentiment analysis, BERT for question answering, ELMo for named entity recognition | [A Survey on Transfer Learning](https://ieeexplore.ieee.org/document/5288526)            |\n",
       "| 4          | Adversarial Training    | Training with examples designed to fool the model            | FGSM attack examples, PGD attack examples, TextFooler | [Adversarial Training for Free!](https://arxiv.org/abs/1904.12843)                       |\n",
       "| 5          | Regularization Techniques | Applying constraints to reduce overfitting and improve generalization | Dropout, L2 regularization, Early stopping | [Regularization for Deep Learning: A Taxonomy](https://arxiv.org/abs/1710.10686)         |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "render.md(openai.chat(*task, tokens=1024, reset=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
